<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>Hypergraph Based Collaborative Film Archive</title>
    <meta name="author" content="Sandeep Reddy Biddala International Institute of Information Technology, Hyderabad (IIIT-H), India and Navjyoti Singh International Institute of Information Technology, Hyderabad (IIIT-H), India"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="Hypergraph Based Collaborative Film Archive"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">Hypergraph Based Collaborative Film Archive</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="BIDDALA_Sandeep_Reddy_Hypergraph_Based_Collaborative_Film_Archive.xml">XML</a>
    </div>
    <p>Digital film archives in addition to preserving cinema should also accommodate and provide for the computation of its cinemas by means of the metadata provided to represent the content in them. The provision for the computation of cinema could lead to various applications like semantic search, automatic genre clustering and classification, special visualization tools, and robust comparisons of movies.</p>
    <p>This paper describes a data model for storing the metadata of a film in an archive based on a discrete theory of cinema that has been in development for the past four years based on Indic theories and other theories of drama and film (Muni, 1996). This theory reduces cinema to a hypergraph composed of tags that assume its full form only with collaborative tagging and extensive visual and textual computing. A system called CinemaScope is also being developed based on this data model which uses HypergraphDB as its database and is being designed and developed to be a semiautomated annotation database system.</p>
    <p>
      <a id="h.6pngm6hadp9c">
        <!--anchor-->
      </a>Overview of Theory
    </p>
    <p>Cinema is ontologically a three-tier structure:</p>
    <p>1. Spatio-temporal flow controlled play of light and sound.</p>
    <p>2. Mere-temporal ‘flow’, which is visually created by a play of 25 fps.</p>
    <p>3. Trans-temporal content, which is embedded in a ‘flow’.</p>
    <p>Cinema concludes in a thematic unity. Unit of a discrete contiguum of cinema is punctuation. Idea of punctuation is inspired by Leibnizian distinction between ideal point and actual point on the one hand and continuum and discrete contiguum on the other (Leibniz, 2013). Punctuation is a form of an actual point that tells apart two recognizable and non-identical discernible contents. It has a structure &lt;entity1|entity2, relational context&gt; or graphically &lt;node1|node2, edge&gt;. </p>
    <p>There are three classes of punctuations based on the three tiers of ontology of cinema:</p>
    <p>1. Temporal punctuation. </p>
    <p>2. Vectorial punctuations between embedded content.</p>
    <p>3. Mereological punctuations between vectorial contents and the thematic conclusion of cinema.</p>
    <p>This way the form of punctuation constitutes discrete contiguum of cinema, which is computationally reducible to a giant graph that tells truth about cinema as art. </p>
    <p>Ontologically there are categories of discrete content that are embedded in punctuated units of flow like shot and episodes. Some of the categories form the content part of the cinematic narrative (like locale, characters, events, and actions) while the rest (camera work, editing, re-recording) form the expressive part of it (Chatman, 1978). Forces operative on these entities as vector punctuations create kinetics of cinema toward thematic conclusion. The motion in films is through the movement of story or plot from the beginning to the conclusion. Such a motion towards theme is punctuated by points of events and points of considerations. It is through the sequence of events that connection to the theme is established. These events are punctuated with points of considerations. Story can be rendered as sequence of the points of events, and under each event there are several considerations (Dhananjaya, 2004). There are scalars between the sequences of cinema that are merely informative and do not account for the motion of the plot.</p>
    <p>
      <a id="h.jm7whto785mz">
        <!--anchor-->
      </a>Overview of Data Model
    </p>
    <p>In Hochin (2006) and Hochin and Tatsuo (2000), a data model called Directed Recursive Hypergraph Data Model (DRHM) has been described in which the content of multimedia is reduced to nodes and edges of a hypergraph. In Radev et al. (1999a; 199b), the structural and behavioral aspects of data that form multimedia information systems have been modelled as a graph-based object-oriented model, and a possible data model for film is shown. These approaches suggest that a graph-based data model for cinema based on the discrete theory of cinema proposed in the previous section would best represent it. Punctuation or point &lt;node | node, edge&gt; can be seen as triple of tags. This will make possible computing of the discrete contiguum of cinema as a graph. Also there are complex relations between the various entities of cinema which is best represented by hyperedges.</p>
    <p>The graph data model should accommodate the various ontological entities and their punctuations, the mereological punctuations as well as the vectors between episodes and the considerations between events. The partial data model for the cinematic hypergraph described is represented in the form of Venn diagram as shown in Figure 1.</p>
    <div class="figure">
      <img src="Pictures/image1.jpg" alt="" class="block" style=" width:9.246305555555555cm; height:7.186083333333333cm;"/>
    </div>
    <p>Figure 1. Venn diagram of cinematic hypergraph—data model.</p>
    <p>Architecture of CinemaScope</p>
    <p>The architecture of the tagging system we propose for CinemaScope is a web-based collaborative one. The annotation schema for the hypergraph data model in theory captures the whole graph. But in practice manual tagging, which is required for the annotating the themes, considerations, meanings, and vectors of cinema, reveals only a sub graph of the original graph. This is because the graph also contains codes and conventions (which are many times dependent on the individual viewer’s perspective) that regulate the narratives and enrich their pure meaning. It is therefore essential that the tagging of the cinema be made social so that most of the graph is captured. The high-level architecture of CinemaScope is given in Figure 2.</p>
    <p>
      <img class="inline" src="Pictures/image2.jpg" alt="" style=" width:13.62075cm; height:10.304638888888888cm;"/>.
    </p>
    <p>Figure 2. Basic architecture of CinemaScope.</p>
    <p>Methodology of CinemaScope</p>
    <p>The database for the system is built on both relational database and graph database (HyperGraphDB). The relational database is used to store all the direct information about the cinema, like its cast, basic plot structure, related files (like script and subtitles), and other relevant information. The graph database is used to graph the tags which have a graphical relation between them. HypergraphDB is a graph-based as well as an object-oriented database with a Java-based API that allows objective modelling of all categories of tags. For example, ontological categories are modelled as follows:</p>
    <p>
      <span style="color:000088">public class</span>
      <span style="color:660066">OntologicalEntity{</span>
    </p>
    <p>
      <span style="color:000088">private</span>
      <span style="color:660066">String</span> entityName 
      <span style="color:666600">;</span>
      <span style="color:880000">//Entity Name</span>
    </p>
    <p>
      <span style="color:000088">private</span>
      <span style="color:660066">Map</span>
      <span style="color:666600">&lt;</span>
      <span style="color:660066">String</span>
      <span style="color:666600">,</span>
      <span style="color:660066">Object</span>
      <span style="color:666600">&gt;</span>attributesNameAndType 
      <span style="color:666600">=</span>
      <span style="color:000088">new</span>
      <span style="color:660066">HashMap</span>
      <span style="color:666600">&lt;</span>
      <span style="color:660066">String</span>
      <span style="color:666600">,</span>
      <span style="color:660066">Object</span>
      <span style="color:666600">&gt;();</span>
      <span style="color:880000">//Contains the attributes with their names and values</span>
    </p>
    <p>
      <span style="color:000088">public void</span> setEntityName 
      <span style="color:666600">(</span>
      <span style="color:660066">String</span> entityName 
      <span style="color:666600">){</span>
    </p>
    <p>//Setting The entity Name</p>
    <p>}</p>
    <p>
      <span style="color:000088">public</span>
      <span style="color:660066">String</span> getEntityName 
      <span style="color:666600">(){</span>
    </p>
    <p>
      <span style="color:000088">return</span> entityName;
    </p>
    <p>}</p>
    <p>
      <span style="color:000088">public</span>
      <span style="color:660066">Object</span> getAttributeValue 
      <span style="color:666600">(</span>
      <span style="color:660066">String</span> attribute 
      <span style="color:666600">){</span>
    </p>
    <p>
      <span style="color:000088">return</span> attributesNameAndType 
      <span style="color:666600">.</span>
      <span style="color:000088">get</span>
      <span style="color:666600">(</span>attribute 
      <span style="color:666600">);</span>
    </p>
    <p>}</p>
    <p>
      <span style="color:000088">public void</span> fillAttribute 
      <span style="color:666600">(</span>
      <span style="color:660066">String</span> value 
      <span style="color:666600">){</span>
    </p>
    <p>/*Code for filling the attributes*/</p>
    <p>}</p>
    <p>}</p>
    <p>The pre-processing stage involves identification of shots, episodes, and the tagging of basic ontological entities. The pre-processing step cannot be completely automated owing to the limitations of current vision and audio processing algorithms. But this stage of the annotation can be aided with a number of supporting files and techniques. For example, movie screenplays and subtitles that are freely available on the Internet help in giving hints of annotation to the user. Even the processes that are completely automated require manual intervention and editing. There are various shot transition detection methods (Boreczky and Rowe, 1996) along with techniques for identification of camera properties like depth, movement, and angle (Benini et al., 2010). The camera properties identified are dependent on the definitions used in the methods, and they are not completely accurate. The tagging system should provide options for manually editing and supervising the shots and camera properties.</p>
    <p>Film scripts and subtitles aid in the tagging of ontological entities by supplying hints. The script is first aligned with the subtitles for time stamps based on the work of Ronfard and Theung (2003). A basic version of this has been implemented based on the work of Larissa Munishkina et al. (2013). An example hint given by the system for the film 
      <span style="font-style:italic">Indiana Jones and the Raiders of the Lost Ark</span> is as follows:
    </p>
    <p>E.g. Scene #1 (0:00–2:15)</p>
    <p>Characters: Indiana Jones, Baranaca</p>
    <p>Locale: High Jungle, Peru</p>
    <p>Things: Gun, Idol</p>
    <p>Events: Shooting, Running</p>
    <p>The Collaborative or Social tagging follows the pre-processing step, and it helps in the creation of tags and links in cinema. The user is given the provision of defining the relations, which is made possible by the use of HyperGraphDB. Hertzum et al. (2002) suggests that collaboration of film archives should facilitate different archives in identifying a common ground on which to base a collaborator and in acknowledging the distinctiveness of each archive. The architecture of CinemaScope allows identifying a common ground, in terms of pre-processing tags as well as distinctiveness, by allowing the users of different background to provide interpretations and considerations of the story in terms of vectors, relations, and links (each with a different label).</p>
    <p>The various relations added by the user and the tags obtained from the pre-processing stage build up the graph, which could later be used for various applications like searching. For example, the following code snippet answers semantic queries like ‘Find all the camera properties used when character is holding the whip’:</p>
    <p>
      <span style="color:660066">HyperGraph</span> graph 
      <span style="color:666600">=</span>
      <span style="color:000088">new</span>
      <span style="color:660066">HyperGraph</span>
      <span style="color:666600">(</span>
      <span style="color:660066">HyperGraphLocation</span>
      <span style="color:666600">);</span>
    </p>
    <p>
      <span style="color:660066">List</span>
      <span style="color:666600">&lt;</span>
      <span style="color:660066">CameraTemporalRelations</span>
      <span style="color:666600">&gt;</span> cameras 
      <span style="color:666600">=</span> hg 
      <span style="color:666600">.</span>getAll 
      <span style="color:666600">(</span>hg 
      <span style="color:666600">.</span>type 
      <span style="color:666600">(</span>
      <span style="color:660066">CameraTemporalRelations</span>
      <span style="color:666600">));</span>
    </p>
    <p>
      <span style="color:660066">List</span>
      <span style="color:666600">&lt;</span>
      <span style="color:660066">CharacterThingTemporalRelations</span>
      <span style="color:666600">&gt;</span> CTR 
      <span style="color:666600">=</span> hg 
      <span style="color:666600">.</span>getAll 
      <span style="color:666600">(</span>hg 
      <span style="color:666600">.</span>
      <span style="color:000088">and</span>
      <span style="color:666600">(</span>hg 
      <span style="color:666600">.</span>type 
      <span style="color:666600">(</span>
      <span style="color:660066">CharacterThingTemporalRelations</span>
      <span style="color:666600">.</span>
      <span style="color:000088">class</span>
      <span style="color:666600">),</span> hg 
      <span style="color:666600">.</span>eq 
      <span style="color:666600">(</span>
      <span style="color:008800">"spatial_relation"</span>
      <span style="color:666600">,</span>
      <span style="color:008800">"hold"</span>
      <span style="color:666600">),</span> hg 
      <span style="color:666600">.</span>eq 
      <span style="color:666600">(</span>
      <span style="color:008800">"thing_name"</span>
      <span style="color:666600">,</span>
      <span style="color:008800">"whip"</span>
      <span style="color:666600">)));</span>
    </p>
    <p>
      <a id="h.u2e32glmo8qr">
        <!--anchor-->
      </a>Summary
    </p>
    <p>The paper describes the discrete theory of cinema and explains the hypergraph data model of cinema. The paper also describes CinemaScope, a semi-automated web-based collaborative film archive based on the hypergraph data model for annotating the film. This project is different from other movie annotation projects (ANSWER, 2009; Jewell et al., 2005); Lombardo and Damiano, 2010), which fail to capture the flow of cinema and make the computational representation of cinema in a database very descriptive and computationally infeasible.</p>
    <div class="figure">
      <img src="Pictures/image3.png" alt="" class="block" style=" width:16.51cm; height:9.278055555555556cm;"/>
    </div>
    <p>Figure 3. Prototype of CinemaScope annotation system.</p>
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w129154aab3b3b1b1b3">
          <div class="biblfree">
            <span style="font-weight:bold">ANSWER Annual Report.</span> (2009). http://cordis.europa.eu/fp7/ict/content-knowledge/docs/answer-annual-report-2009.pdf.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1b5">
          <div class="biblfree">
            <span style="font-weight:bold">Benini, S., Canini, L. and Leonardi, R.</span> (2010). Estimating Cinematographic Scene Depth in Movie Shots. Multimedia and Expo (ICME), 2010 IEEE International Conference.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">Boreczky, J. S. and Rowe, L. A.</span> (1996). Comparison of Video Shot Boundary Detection. 
            <span style="font-style:italic">Journal of Electronic Imaging,</span>
            <span style="font-weight:bold">5</span>(2) (April): 122–28.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1b9">
          <div class="biblfree">
            <span style="font-weight:bold">Chatman, S.</span> (1978). 
            <span style="font-style:italic">Story and Discourse: Narrative Structure in Fiction and Film</span>. Cornell University Press, Ithaca, NY.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c11">
          <div class="biblfree">
            <span style="font-weight:bold">Dhananjaya.</span> (1100). Dasarupaka, Dr. Keshavrao Musalgaunkar. Hindi Dasarupaka, 2004.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c13">
          <div class="biblfree">
            <span style="font-weight:bold">Hertzum, M., Pejtersen, A. M., Cleal, B. and Albrechtsen, H.</span> (2002). An Analysis of Collaboration in Three Film Archives: A Case for Collaboratories. 
            <span style="font-style:italic">CoLIS4: Proceedings of the Fourth International Conference on Conceptions of Library and Information Science.</span> Libraries Unlimited, pp. 69–83.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c15">
          <div class="biblfree">
            <span style="font-weight:bold">Hochin, T.</span> (2006). Graph-Based Data Model for the Content Representation of Multimedia Data. Knowledge-Based Intelligent Information and Engineering Systems. 
            <span style="font-style:italic">Lecture Notes in Computer Science,</span>
            <span style="font-weight:bold">4252</span> (1182–90).
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c17">
          <div class="biblfree">
            <span style="font-weight:bold">Hochin, T. and Tatsuo T.</span> (2000). A Directed Recursive Hypergraph Data Model for Representing the Contents of Multimedia Data. 
            <span style="font-style:italic">Memoirs of the Faculty of Engineering, Fukui University, </span>
            <span style="font-weight:bold">48</span>: 343–60.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c19">
          <div class="biblfree">
            <span style="font-weight:bold">Jewell, M., Lawrence, K., Tuffield, M., Prugel-Bennett, A., Millard, D., Nixon, M. and Shadbolt, N.</span> (2005). OntoMedia: An Ontology for the Representation of Heterogeneous Media. 
            <span style="font-style:italic">Proceedings of SIGIR Workshop on Multimedia Information Retrieval.</span> ACM.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c21">
          <div class="biblfree">
            <span style="font-weight:bold">Leibniz, G. W.</span> (2013). 
            <span style="font-style:italic">The Labyrinth of the Continuum: Writings on the Continuum Problem 1672–1686</span>. Translated, edited, and with an introduction by Richard T. W. Arthur. Yale University Press, New Haven, CT.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c23">
          <div class="biblfree">
            <span style="font-weight:bold">Lombardo, V. and Damiano, R.</span> (2010). Narrative Annotation and Editing of Video. Interactive Storytelling. 
            <span style="font-style:italic">Lecture Notes in Computer Science,</span>
            <span style="font-weight:bold">6432</span>, 62–73.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c25">
          <div class="biblfree">
            <span style="font-weight:bold">Muni, B.</span> (1996 [300 BC]). 
            <span style="font-style:italic">Nāṭya śāstra</span>. With Abhinavagupta’s Commentary; with Hindi Commentary by Dwivedi Parasnath. Sampurnanand Sanskrit Mahavidyalaya, Varanasi.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c27">
          <div class="biblfree">
            <span style="font-weight:bold">Munishkina, L., Parrish, J. and Walker, M. A.</span> (2013). Fully Automatic Interactive Story Design from Film Scripts. Interactive Storytelling. 
            <span style="font-style:italic">Lecture Notes in Computer Science,</span>
            <span style="font-weight:bold">8230</span>: 229–32.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c29">
          <div class="biblfree">
            <span style="font-weight:bold">Radev, I., Pissinou, N. and Makki, K.</span> (1999a). Film Video Modeling. 
            <span style="font-style:italic">Proceedings of IEEE Workshop on Knowledge and Data Engineering Exchange, KDEX 99</span>, Chicago, IL, November 1999.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c31">
          <div class="biblfree">
            <span style="font-weight:bold">Radev, I., Pissinou, N., Makki, K. and Park, E. K. </span>(1999b). Graph-Based Object-Oriented Approach for Structural and Behavioral Representation of Multimedia Data. 
            <span style="font-style:italic">Proceedings of the Eighth International Conference on Information and Knowledge Management</span>, Kansas City, MO, 2–6 November 1999, pp. 522–30.
          </div>
        </li>
        <li id="index.xml-bibl-w129154aab3b3b1b1c33">
          <div class="biblfree">
            <span style="font-weight:bold">Ronfard, R. and Thuong, T. T.</span> (2003). A Framework for Aligning and Indexing Movies with Their Script. 
            <span style="font-style:italic">Proceedings of ICME</span>, Baltimore, MD, 6–9 July 2003.
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Sandeep Reddy Biddala (biddala.sandeepreddy@gmail.com), International Institute of Information Technology, Hyderabad (IIIT-H), India and Navjyoti Singh (navjyoti@iiit.ac.in), International Institute of Information Technology, Hyderabad (IIIT-H), India</address>
    </div>
  </body>
</html>
