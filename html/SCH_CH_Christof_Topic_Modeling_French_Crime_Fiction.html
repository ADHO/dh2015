<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>Topic Modeling French Crime Fiction</title>
    <meta name="author" content="Christof Schöch University of Würzburg, Germany"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="Topic Modeling French Crime Fiction"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">Topic Modeling French Crime Fiction</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="SCH_CH_Christof_Topic_Modeling_French_Crime_Fiction.xml">XML</a>
    </div>
    <p>This study applies topic modeling to a collection of French crime fiction novels in order to discover topic-related patterns. The results show both expected and unexpected patterns related to authors, subgenres, and time period. Topic modeling proves highly useful for investigating the history of French crime fiction. </p>
    <p>French Crime Fiction</p>
    <p>Crime fiction is a type of narrative prose fiction involving the elucidation of a (usually) violent crime through a (more or less) rational investigation (often) taking place in an urban setting and (typically) involving (one or several) investigators, victims, witnesses, suspects, and criminals. French crime fictionʼs rich history goes back to the 1860s and has many highly prolific proponents. Prototypical detective fiction is easily recognized, but the boundaries of the genre and its internal division into subgenres remain controversial (see Todorov, 1971; Lits, 1993; Colin, 1999; Lavergne, 2009). The abundant material is a challenge to any readerʼs memory but an opportunity for quantitative methods.</p>
    <p>Research Questions</p>
    <p>This study addresses the following questions: How prevalent are expected, genre-related topics such as crime and investigation, and which other topics are important? What relations exist between topics and categories like authorship, subgenre, or time period? What kind of groupings of novels does one obtain based on topic similarity? What new insights into the history of crime fiction does topic modeling allow?</p>
    <p>Data</p>
    <p>For this study, a collection of 270 French novels published between 1858 and 2012 was created. The vast majority are crime fiction novels, but some non–crime fiction novels have also been included. The collection includes novels pertaining to seven subgenres and written by 14 different authors. It has around 16 million word tokens. Texts in the public domain have been obtained online (from ebooksgratuits.com), while additional texts have been obtained by full-text digitization.</p>
    <p>Method</p>
    <p>Topic modeling is an unsupervised method of discovering latent semantic structure in large collections of texts. Technically, a topic is a probability distribution over word frequencies, and each text is characterized by a distribution over topics (see Steyvers and Griffiths, 2006). In practice, the words with the highest scores in a given topic are mostly semantically related words; the topics with the highest scores in a text represent the textʼs major themes or motives. </p>
    <p>The most widely known algorithm is Latent Dirichlet Allocation (LDA; see Blei et al., 2003), but several precursors and alternatives exist—for instance, Non-Negative Matrix Factorization (Lee and Seung, 1999). Several tools are available, like MALLET (McCallum, 2002) or gensim (Rehurek and Sojka, 2010), as well as tutorials (e.g., Graham et al., 2012, Riddell, 2014). Topic modeling has proven immensely popular in digital humanities (e.g., Blevins, 2010; Rhody, 2012; Jockers, 2013).</p>
    <p>For the results reported here, the following parameters have been used: Lemmatization has been applied to the texts, because French is a highly inflected language. After POS-tagging with TreeTagger (Schmid, 1994), nouns have exclusively been selected for analysis. Each novel has then been split into segments of approximately 150 nouns each. MALLET has been run with 60 target topics and 10,000 iterations. </p>
    <p>Results and Discussion</p>
    <p>Topics Obtained</p>
    <p>The topics obtained can manually be labeled by their dominant semantic trait (see Figure 1).</p>
    <p>Figure 1. Selection from the 60 topics obtained (with topic ID and 20 top-ranked words).</p>
    <p>The subjective topic coherence is very high: few top-ranked words do not share semantic traits, and few topics are hard to interpret (but see Chang et al., 2009; Schmidt, 2012). Many topics could appear in any type of novels, such as topics #28, #38, and #01 (labeled ‘family’, ‘money’, ‘train’). Only nine out of 60 topics are related to crime fiction, such as #15, #33, and #53 (labeled ‘investigators’, ‘fire arms’, ‘jewelry’). Judged by topic composition alone, crime fiction appears to be a less distinctive novelistic sub-genre than expected. Note that topics are based on various types of similarity: topic #44 (‘interiors’) is related to a recurrent setting, topic #22 (“informal1”) to a specific register.</p>
    <p>Authorship, Subgenre, and Time</p>
    <p>Topic scores per text segment can be aggregated and averages obtained, for instance, at the document, author, genre, or time period levels. </p>
    <p>On the author level (see Figure 2), it appears that several (but not all) authors have a distinctive ‘signature topic’: a topic with a particularly high score in comparison both to other topics for the same author and to the same topic for other authors (i.e., across rows and columns). </p>
    <div class="figure">
      <i>[figure]</i>
    </div>
    <p>Figure 2. Distribution of topic scores at the author level (15 topics with the largest variation across authors, measured in standard deviations).</p>
    <p>Gaboriau 
      <a id="_DdeLink__562_1474829924">
        <!--anchor-->
      </a>ʼs signature topic is very general (#11, ‘bourgeoisie’) while Simenonʼs is more genre-specific (#29, ‘office’) and Maletʼs is not thematic (#22, ‘informal1’). For some authors (Leroux, Manchette, Ponson), no clear signature topic emerges.
    </p>
    <p>Compared to authors, most subgenres have less marked characteristic topics (Figure 3).</p>
    <div class="figure">
      <img src="Pictures/image3.jpeg" alt="" class="block" style=" width:13.999986111111111cm; height:9.607902777777777cm;"/>
    </div>
    <p>Figure 3. Topic scores aggregated to the subgenre level (20 topics with the largest variation, measured in standard deviations, across genres).</p>
    <p>For example, the classical detective novelʼs most characteristic topic is #29 (‘office’). However, the traditional genre labels used here are problematic, because they tend to refer to periods rather than structural types and correlate strongly with authorship. </p>
    <p>When average topic scores are obtained across all novels for each successive tenths of novels, and topic score progressions are compared across subgenres, genre-specific patterns appear (see Figure 4). </p>
    <div class="figure">
      <img src="Pictures/image4.jpeg" alt="" class="block" style=" width:16.002cm; height:5.499805555555556cm;"/>
    </div>
    <p>Figure 4. Topic score progression for topic #26 (average topic scores per text segment and subgenre).</p>
    <p>For instance, topic #26 (‘twilight’) decreases over the course of the average detective fiction novel, but remains stable at a higher level over the course of ‘roman noir’. In the former, darkness and uncertainty are being dispelled and order restored, while in the latter, they are not. </p>
    <p>The distribution of topics at the level of time period (Figure 5) shows that, as expected, some topics gain while others lose in importance over time. Some very similar topics ‘take turns’, as it were, with successive peaks (‘informal’, right). Others reflect larger societal changes (different means of 
      <img class="block" src="Pictures/image5.jpeg" alt="" style=" width:16.002cm; height:5.499805555555556cm;"/>communication, left).
    </p>
    <p>Figure 5. Topic scores per decade for two topic groups.</p>
    <p>For the ‘informal’ topics, each peak is associated with one author and their period of activity: Malet, Dard, and Vargas (see Figure 2). The topicʼs rapid rise in the 1940s underlines how bold Maletʼs use of informal language was, but also shows the (problematic) impact of individual authors on these temporal patterns.</p>
    <p>Beyond individual topic development over time, the cumulated rate of change in topic scores from one decade to the next gives an insight into the thematic innovation cycles of crime fiction (Figure 6). </p>
    <div class="figure">
      <img src="Pictures/image6.jpeg" alt="" class="block" style=" width:11.999736111111112cm; height:7.999236111111111cm;"/>
    </div>
    <p>Figure 6. Cumulated absolute differences between topic scores from one decade to the next.</p>
    <p>Values above trendline indicate periods of intense topic-related innovation and, possibly, generational shifts (notably, 1880s–1900s and 1930s–1940s). Values below indicate periods of relative continuity (notably, 1910s–1920s and 1940s–1960s). Such results provide a fresh perspective on periodization in literary history. </p>
    <p>Author Similarity</p>
    <p>Based on the topic scores per novel, author, or genre, Principal Component Analysis (see Joliffe, 2002) yields groupings of topically similar items, independently of preexisting classifications. The PCA plots in Figure 7 are based on topic scores aggregated to the author </p>
    <p>level and have been obtained 
      <img class="block" src="Pictures/image7.jpeg" alt="" style=" width:16.00023611111111cm; height:6.932083333333333cm;"/>using the stylo package for R (Eder et al., 2013). The first two components retain large parts of the variation in the data (31.3% and 12.6%, respectively).
    </p>
    <p>Figure 7. PCA plot of aggregated topic scores per author: authors (right) and loadings (left).</p>
    <p>Not surprisingly for a collection of texts spanning 150 years, the first component is correlated </p>
    <p>with time period: authors active before 1930 are located to the east of the plot, those active from 1930 to 1960 close to the middle, and those active after 1960 to the west. A notable exception is Fred Vargas: although writing in the late twentieth century, she appears close to Malet and Dard: the topic-based grouping reveals a link between the now classic ‘roman noir’ and its later reinterpretation by Vargas. Note that although the three authors each have an ‘informal’ topic as their ‘signature topic’ (see above), their proximity remains unchanged even when these topics are removed. Japrisotʼs unique work rightly stands out, but his relative proximity to Simenon remains to be explained. </p>
    <p>Conclusions and Future Work </p>
    <p>The results obtained here shed a new light on the history of French crime fiction. Authors, subgenres, and time periods each have distinctive topic characteristics. Some well-understood facts about the genre can be confirmed (e.g., author groupings), but new insights into the genreʼs thematic history also become possible (e.g., thematic innovation cycles). Topic modeling proves to be a valuable tool, providing a fresh perspective on literary history and prompting new interrogations about periodization and the contours of subgenres. </p>
    <p>Future work will involve two areas: The text collection will be expanded to reduce correlation between authors, subgenres, and time period. Also, the precise relation between topics and certain categories (e.g., subgenres) will be further investigated using supervised/labeled topic modeling (see McAuliffe and Blei, 2008; Ramage et al., 2009). </p>
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w673984aab3b3b1b1b3">
          <div class="biblfree">
            <span style="font-weight:bold">Blei, D. M., Griffiths, T., Jordan, M. I. and Tenenbaum, J. B.</span> (2004). Hierarchical Topic Models and the Nested Chinese Restaurant Process. In Thrun, S., Saul, L. K. and Schölkopf, B. (eds), 
            <span style="font-style:italic">Advances in Neural Information Processing Systems 16</span>. MIT Press, Cambridge, MA.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1b5">
          <div class="biblfree">
            <span style="font-weight:bold">Blei, D. M., Ng, A. Y. and Jordan, M. I.</span> (2003). Latent Dirichlet Allocation. 
            <span style="font-style:italic">Journal of Machine Learning Research</span>, 
            <span style="font-weight:bold">3</span>: 993–1022.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">Blevins, C.</span> (2010). Topic Modeling Martha Ballard’s Diary. http://historying.org/2010/04/01/topic-modeling-martha-ballards-diary/.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1b9">
          <div class="biblfree">
            <span style="font-weight:bold">Chang, J., Boyd-Graber, J. L., Gerrish, S., Wang, C. and Blei, D. M.</span> (2009). Reading Tea Leaves: How Humans Interpret Topic Models. In 
            <span style="font-style:italic">Advances in Neural Information Processing Systems 22</span>, pp. 288–96.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c11">
          <div class="biblfree">
            <span style="font-weight:bold">Colin, J.-P.</span> (1999). 
            <span style="font-style:italic">La belle époque du roman policier français. Aux origines d’un genre romanesque</span>. Delachaux et Niestlé, Lausanne.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c13">
          <div class="biblfree">
            <span style="font-weight:bold">Eder, M., Kestemont, M. and Rybicki, J.</span> (2013). Stylometry with R: A Suite of Tools. In 
            <span style="font-style:italic">Digital Humanities 2013: Conference Abstracts</span>. Lincoln: University of Nebraska, pp. 487–89.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c15">
          <div class="biblfree">
            <span style="font-weight:bold;color:222222">Graham, S., Weingart, S. and Milligan, I.</span>
            <span style="color:222222">(2012). Getting Started with Topic Modeling and MALLET. The Programming Historian, </span>http://programminghistorian.org/lessons/topic-modeling-and-mallet 
            <span style="color:222222">.</span>
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c17">
          <div class="biblfree">
            <span style="font-weight:bold">Jockers, M. L.</span> (2013). 
            <span style="font-style:italic">Macroanalysis: Digital Methods and Literary History</span>. University of Illinois Press.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c19">
          <div class="biblfree">
            <span style="font-weight:bold">Joliffe, I. T.</span> (2002). 
            <span style="font-style:italic">Principal Component Analysis</span>. 2nd ed. Springer.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c21">
          <div class="biblfree">
            <span style="font-weight:bold">Lavergne, E.</span> (2009). 
            <span style="font-style:italic">La naissance du roman policier français</span>. Garnier, Paris.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c23">
          <div class="biblfree">
            <span style="font-weight:bold">Lee, D.D. and Seung, H. S.</span> (1999). Learning the Parts of Objects by Non-Negative Matrix Factorization. 
            <span style="font-style:italic">Nature,</span>
            <span style="font-weight:bold">401</span>(6755): 788–91.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c25">
          <div class="biblfree">
            <span style="font-weight:bold">Lits, M.</span> (1993). 
            <span style="font-style:italic">Le roman policier. Introduction à la théorie et l’histoire d’un genre littéraire</span>. CÉFAL, Liège.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c27">
          <div class="biblfree">
            <span style="font-weight:bold">Mcauliffe, J. D. and Blei, D. M.</span> (2008). Supervised Topic Models. In Platt, J. C., Koller, D. Singer, Y. and Roweis, S. T. (eds), 
            <span style="font-style:italic">Advances in Neural Information Processing Systems 20</span>, http://papers.nips.cc/paper/3328-supervised-topic-models.pdf, pp. 121–28.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c29">
          <div class="biblfree">
            <span style="font-weight:bold">McCallum, A. K.</span> (2002). 
            <span style="font-style:italic">MALLET: A Machine Learning for Language Toolkit.</span> http://mallet.cs.umass.edu.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c31">
          <div class="biblfree">
            <span style="font-weight:bold">Mesplède, C.</span> (ed.). (2007). 
            <span style="font-style:italic">Dictionnaire des littératures policières</span>. Joseph K., Paris.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c33">
          <div class="biblfree">
            <span style="font-weight:bold">Ramage, D., Hall, D., Nallapati, R. and Manning, C. D.</span> (2009). Labeled LDA: A Supervised Topic Model for Credit Attribution in Multi-labeled Corpora. In 
            <span style="font-style:italic">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1</span>, pp. 248–56.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c35">
          <div class="biblfree">
            <span style="font-weight:bold">Rehurek, R., Sojka, P.</span> (2010). Software Framework for Topic Modelling with Large Corpora. In 
            <span style="font-style:italic">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</span>, Valletta, Malta: ELRA, pp. 45–50.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c37">
          <div class="biblfree">
            <span style="font-weight:bold">Rhody, L. M.</span> (2012). Topic Modeling and Figurative Language. 
            <span style="font-style:italic">Journal of Digital Humanities,</span>
            <span style="font-weight:bold">2</span>(1), http://journalofdigitalhumanities.org/2-1/topic-modeling-and-figurative-language-by-lisa-m-rhody/.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c39">
          <div class="biblfree">
            <span style="font-weight:bold">Riddell, A. B.</span> (2014). Text Analysis with Topic Models for the Humanities and Social Sciences (TAToM). DARIAH-DE, https://de.dariah.eu/tatom/.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c41">
          <div class="biblfree">
            <span style="font-weight:bold">Rubin, T. N., Chambers, A., Smyth, P. and Steyvers, M.</span> (2012). Statistical Topic Models for Multi-Label Document Classification. 
            <span style="font-style:italic">Machine Learning,</span>
            <span style="font-weight:bold">88</span>(1–2): 157–208, doi:10.1007/s10994-011-5272-5.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c43">
          <div class="biblfree">
            <span style="font-weight:bold">Schmid, H.</span> (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. In 
            <span style="font-style:italic">Proceedings of International Conference on New Methods in Language Processing</span>, Manchester, UK.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c45">
          <div class="biblfree">
            <span style="font-weight:bold">Schmidt, B. M.</span> (2012). Words Alone: Dismantling Topic Models in the Humanities. 
            <span style="font-style:italic">Journal of Digital Humanities,</span>
            <span style="font-weight:bold">2</span>(1), http://journalofdigitalhumanities.org/2-1/words-alone-by-benjamin-m-schmidt/.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c47">
          <div class="biblfree">
            <span style="font-weight:bold">Steyvers, M. and Griffiths, T.</span> (2006). Probabilistic Topic Models. In Landauer, T., McNamara, D., Dennis, S. and Kintsch, W. (eds), 
            <span style="font-style:italic">Latent Semantic Analysis: A Road to Meaning</span>. Laurence Erlbaum.
          </div>
        </li>
        <li id="index.xml-bibl-w673984aab3b3b1b1c49">
          <div class="biblfree">
            <span style="font-weight:bold">Todorov, T.</span> (1971). Typologie du roman policier. In 
            <span style="font-style:italic">Poétique de la prose</span>. Paris: Seuil, pp. 55–65.
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Christof Schöch (christof.schoech@uni-wuerzburg.de), University of Würzburg, Germany</address>
    </div>
  </body>
</html>
