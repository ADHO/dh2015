<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>"Sonic Materialization of Linguistic Data" (working title)</title>
    <meta name="author" content="Nadia Paraskevoudi Sonic Linguistics, Greece and Timos Alexandropoulos Sonic Linguistics, Greece"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="&quot;Sonic Materialization of Linguistic Data&quot; (working title)"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">"Sonic Materialization of Linguistic Data" (working title)</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="PARASKEVOUDI_Nadia__Sonic_Materialization_of_Linguistic_Data___working_title_.xml">XML</a>
    </div>
    <p>
      <span style="font-weight:bold">The Problem of Sonification</span>
    </p>
    <p>Kramer Gregory (1994), in his book 
      <span style="font-style:italic">Auditory Display: Sonification, Audification, and Auditory Interfaces</span>, defines sonification as ‘use of non-speech audio to convey information or perceptualize data’.
    </p>
    <p>In our digital age we can store, edit, and examine almost all qualities and quantities as data. Sound itself can be considered as a pure stream of information able to be modulated, transformed, and analyzed in a lot of different ways. </p>
    <p>The success of sonification occurs when the sound reveals one or more qualities of data or data reveals one or more qualities of sound. Thus, this kind of materialization of data is an interdisciplinary act that involves the proper analysis of data as well as the structure of sound. </p>
    <p>While technology provides us with a wide variety of tools, the core of the problem still exists. As this kind of interdisciplinary knowledge is hard to be combined, there aren’t enough available tools that help artists to escape from an arbitrary mapping of data to sound qualities. This leads to arbitrary results both for the artist and the listener as the sonification process doesn’t take advantage of either the auditory perception properties or sound’s advantages in temporal, amplitude, and frequency resolution. As a result, in most cases, sonification fails its purpose, which ‘is to encode and convey information about an entire data set or relevant aspects of the data set’ (Hermann et al., 2011). </p>
    <p>
      <span style="font-weight:bold">Sound and Linguistics</span>
    </p>
    <p>Sonic Materialization of Linguistic Data is a series of works and a research project aiming to provide sound artists with the tools for the proper linguistic analysis of the mined data. </p>
    <p>In our age of constant connectivity, social media—and especially the text-based Twitter platform—can be considered as a monitor corpus that evolves perpetually and is in a process of constant change. In order to create new structures and transform this chaotic stream of data into new material—in our case, sound—it needs to be organized according to its different kind of properties, namely here, its linguistic aspects 
      <span style="font-weight:bold">. </span>With our Sonic Materialization of Linguistic Data work, we provide different software modules that can perform real-time linguistic analysis of data and output the result for sonification purposes.
    </p>
    <p>Our software consists of different kind of modules from which the user can choose only one or a combination of more. Here we present the 
      <span style="font-style:italic">Stress Module</span>. The program enables the user to aggregate data from different hashtag [#] feeds on Twitter in real time. The incoming data is being processed according to their linguistic features and in particular stress. The algorithm performs a series of tasks and extracts the stressed syllables of the aforementioned data. The output is a phonetic transcription code that represents each phoneme of the input Twitter feed. The encoded outputted list of data also includes suggestions for the sonic mapping that occurs from data’s linguistic features and the sound’s nature. For instance, the strong syllables are a numerical output that represents a longer sound event (time envelope), whereas the weaker syllables are a numerical representation of a briefer sound event. Similar kinds of optional mapping can also affect other sound features, such as pitch, timbre, ADSR envelopes, modulation, etc.
    </p>
    <p>Stress, which can be considered as a prosodic feature, manifests itself in the speech stream in several ways. Stress patterns seem to be highly language dependent, considering that there is a dichotomy between stress-timed and syllable-timed languages. In stress-timed languages, primary stress occurs at regular intervals, regardless of the number of unstressed syllables in between, whereas in syllable-timed languages syllables tend to be equal in duration and therefore are inclined to follow each other at regular intervals of time. According to Halliday, ‘Salient syllables occur in stress-timed languages at regular intervals’ (1985, 272). Strong syllables bear primary or secondary stress and contain full vowels, whereas weak syllables are unstressed and contain short, central vowels. </p>
    <p>Particularly in English, which is a stress language, speech rhythm has a characteristic pattern that is expressed in the opposition of strong versus weak syllables. Stressed syllables in English are louder, but they also tend to be longer and have a higher pitch. Despite the fact that stress can be also influenced by pragmatic factors such as emphasis, our project aims to capture the natural stress pattern of English in order to extract meaning from sound patterns, too, as they will be delineated by the phonetic structure of natural language. </p>
    <p>
      <span style="font-weight:bold">Presentation</span>
    </p>
    <p>For the presentation of the project we are proposing a poster with the description of how exactly the software works and what its aim is. We also would like to include a pair of headphones and a small screen (or projector) in order to have the data analysis and the sonification process in real time for the audience to experience. </p>
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w577815aab3b3b1b1b3">
          <div class="biblfree">
            <span style="font-weight:bold">Halliday, M. A. K.</span> (1985). 
            <span style="font-style:italic">An Introduction to Functional Grammar</span>. Arnold, London.
          </div>
        </li>
        <li id="index.xml-bibl-w577815aab3b3b1b1b5">
          <div class="biblfree">
            <span style="font-weight:bold;color:242424">Hermann, T., Hunt, A. and Neuhoff, J. G.</span>
            <span style="color:242424">(eds). (2011). </span>
            <span style="font-style:italic;color:242424">The Sonification Handbook</span>
            <span style="color:242424">. </span>Logos Verlag Berlin, Berlin.
          </div>
        </li>
        <li id="index.xml-bibl-w577815aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">Kramer, G.</span> (1994). Auditory Display: Sonification, Audification, and Auditory Interfaces. 
            <span style="font-style:italic">Santa Fe Institute Studies in the Sciences of Complexity, Proceedings Vol. XVIII</span>. Addison Wesley, Reading, MA.
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Nadia Paraskevoudi (nadiaparask@gmail.com), Sonic Linguistics, Greece and Timos Alexandropoulos (timosalexandropoulos@gmail.com), Sonic Linguistics, Greece</address>
    </div>
  </body>
</html>
