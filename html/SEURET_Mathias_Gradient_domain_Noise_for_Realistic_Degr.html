<?xml version="1.0" encoding="UTF-8"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
    <title>Gradient-domain Noise for Realistic Degradations in Historical Documents Images</title>
    <meta name="author" content="Mathias Seuret University of Fribourg, Switzerland , Nicole Eichenberger University of Fribourg, Switzerland , Marcus Liwicki University of Fribourg, Switzerland , and Rolf Ingold University of Fribourg, Switzerland"/>
    <meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
    <meta name="DC.Title" content="Gradient-domain Noise for Realistic Degradations in Historical Documents Images"/>
    <meta name="DC.Type" content="Text"/>
    <meta name="DC.Format" content="text/html"/>
    <link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
    <link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
  </head>
  <body class="simple" id="TOP">
    <div class="stdheader autogenerated">
      <h1 class="maintitle">Gradient-domain Noise for Realistic Degradations in Historical Documents Images</h1>
    </div>
    <div class="dhconvalidator-xml-link">
      <a href="SEURET_Mathias_Gradient_domain_Noise_for_Realistic_Degradations_in_Historical_Documents_Images.xml">XML</a>
    </div>
    <p>We developed a novel method for adding realistic degradations to color document images in order to generate large sets of training data for computational processing. We extract and process patches of real noise from degraded documents and paste them into the target document image using the gradient domain in order to achieve independence from the hue of the document. We will describe the novel algorithm and present an expert’s opinion on the data generated.</p>
    <p>* * *</p>
    <p>Historical documents suffer from different kinds of damages during their conservation, caused by either constant use (e.g., stains, fingermarks, ink strokes or spots, scratches, degradation of ink by abrasion), by inappropriate storage conditions (such as mildew caused by humidity), by historical catastrophes like wars, or by the material itself (such as ink corrosion). These damages can affect the readability of the manuscripts and also pose a severe challenge for digital processing of such documents.</p>
    <p>Developing robust digital processing algorithms requires machine learning, which relies on huge amounts of realistic training data, i.e., large sets of document images together with their corresponding ground truth (which refers to the expected labeling of the document). The high cost of ground-truthing limits the number of available training and testing documents. This motivates the development of methods that artificially add noise to existing ground-truthed documents in order to increase the number of available training documents.</p>
    <p>Fischer et al. (2013) presented a method to generate training samples by deforming binarized text lines. They showed that the accuracy of text recognition could be increased by up to 3.23% by their method.</p>
    <div class="figure">
      <img src="Pictures/image1.png" alt="" class="inline" style=" width:11.297708333333333cm; height:5.662083333333333cm;"/>
    </div>
    <p>Figure 1. An document image sample (left) and its degraded version (right).</p>
    <p>Kieu et al. (2012) have presented a local noise generation method for historical document gray-scale images. They evaluated their method with optical characters recognition (OCR) software and found a linear relation between the quantity of the noise and the recognition error rate. Several other methods have been developed, but they all work either on the red, green, and blue values of images, or on binary (black-and-white) images.</p>
    <p>Methodology</p>
    <p>The main novelty of our method is, contrary to previous work, to work in the gradient domain of color images, i.e., using the difference of values between pixels, and to use patches of real degradations from existing document images.</p>
    <p>To insert degradation patches in the gradient domain, we first compute the gradients of the document image and of the degradation patches, then paste the gradients of the degradations on the gradients of the document image, and finally reconstruct the document image from its modified gradients. This method is illustrated in Figure 1. Working in the RGB color space would lead to inconsistencies if the document from which we extracted the degradations does not have a very similar background color as our target document image. Working in the gradient domain to avoid this is the main novelty of our method.</p>
    <p>Our method is inspired by the Poisson image editing method presented by Pérez et al. (2003). First, we compute the horizontal and vertical gradients of the image. Then we apply the degradations on these gradients. Finally, we construct the result image from the modified gradients.</p>
    <p>Scholar’s Point of View</p>
    <p>From a manuscript scholar’s point of view, the method for adding synthetic noise presents advantages and disadvantages regarding its verisimilitude. One advantage is that the inserted patches are based on real degradations appearing in historical documents; thus, they represent realistic historical degradations. This method provides a rather realistic impression for small-sized details of a manuscript page. However, the overall impression of an entire page looks less realistic, because the degradation patches are spread repeatedly, following a uniform random distribution over the page, and can easily be recognized as artificially added. Thus, the gradient method is appropriate for simulating degradations such as stains, scratches, and ink spots, which mostly overlap the script or the background, but doesn’t have a direct impact on the script (as, for example, abrasion and humidity do). It works best on small-scale details.</p>
    <p>Discussion</p>
    <p>Our method can be used to generate document images to train machine learning algorithms. The settings of the software that we developed are easy to manipulate by non–computer scientists. However, precautions have to be taken in order to clarify that the resulting degraded documents do not represent the actual state of the real historical document. As future work, we will compute statistics about the position of the degradations while extracting patches in order to generate more realistic distribution models.</p>
    <div class="bibliogr" id="index.xml-back.1_div.1">
      <h2>
        <span class="headingNumber">Appendix A </span>
      </h2>
      <div class="listhead">Bibliography</div>
      <ol class="listBibl">
        <li id="index.xml-bibl-w683082aab3b3b1b1b3">
          <div class="biblfree">
            <span style="font-weight:bold">
              <span style="color:222222">Fischer</span>
              <span style="color:222222">,</span>
              <span style="color:222222">A., </span>
              <span style="color:222222">Visani</span>
              <span style="color:222222">,</span>
              <span style="color:222222">M., </span>
              <span style="color:222222">Kieu</span>
              <span style="color:222222">, </span>
              <span style="color:222222">C. V. </span>
              <span style="color:222222">and </span>
              <span style="color:222222">Suen</span>
              <span style="color:222222">,</span>
              <span style="color:222222">C. Y.</span>
            </span>
            <span style="color:222222">(2013). Generation of Learning Samples for Historical Handwriting Recognition Using Image Degradation. In </span>
            <span style="font-style:italic;color:222222">Proceedings of the 2nd International Workshop on Historical Document Imaging and Processing</span>
            <span style="color:222222">, pp. 73–79.</span>
          </div>
        </li>
        <li id="index.xml-bibl-w683082aab3b3b1b1b5">
          <div class="biblfree">
            <span style="font-weight:bold">
              <span style="color:222222">Kieu</span>
              <span style="color:222222">, </span>
              <span style="color:222222">C. V., </span>
              <span style="color:222222">Visani</span>
              <span style="color:222222">,</span>
              <span style="color:222222">M., </span>
              <span style="color:222222">Journet</span>
              <span style="color:222222">, N., </span>
              <span style="color:222222">Domenger</span>
              <span style="color:222222">J.-P.</span>
              <span style="color:222222">and</span>
              <span style="color:222222">Mullot</span>
              <span style="color:222222">,</span>
              <span style="color:222222">R.</span>
            </span>
            <span class="apple-converted-space">
              <span style="color:222222"> </span>
            </span>
            <span style="color:222222">(2012). A Character Degradation Model for Grayscale Ancient Document Images. In </span>
            <span style="font-style:italic;color:222222">21st International Conference on Pattern Recognition (ICPR),</span>
            <span style="color:222222">pp. 685–88.</span>
          </div>
        </li>
        <li id="index.xml-bibl-w683082aab3b3b1b1b7">
          <div class="biblfree">
            <span style="font-weight:bold">Pérez, P., Gangnet, M. and Blake, A.</span> (2003). Poisson Image Editing. In 
            <span style="font-style:italic">ACM Transactions on Graphics (TOG),</span> pp. 313–18.
          </div>
        </li>
      </ol>
    </div>
    <div class="stdfooter autogenerated">
      <address>Mathias Seuret (mathias.seuret@unifr.ch), University of Fribourg, Switzerland and Nicole Eichenberger (nicole.eichenberger@unifr.ch), University of Fribourg, Switzerland and Marcus Liwicki (marcus.eichenberger-liwicki@unifr.ch), University of Fribourg, Switzerland and Rolf Ingold (rolf.ingold@unifr.ch), University of Fribourg, Switzerland</address>
    </div>
  </body>
</html>
